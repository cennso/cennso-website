concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true
name: Lighthouse Performance Check
on:
  pull_request_target:
    types:
      - opened
      - reopened
      - synchronize
      - ready_for_review
jobs:
  lighthouse:
    name: Run Lighthouse audits
    permissions:
      contents: read
      pull-requests: write
    defaults:
      run:
        working-directory: ./
    runs-on: ubuntu-22.04
    steps:
      - name: Check out repository
        uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.sha }}  # pull_request_target defaults to base branch, so explicitly checkout PR code
      - name: Wait for Vercel deployment
        uses: patrickedqvist/wait-for-vercel-preview@06c79330064b0e6ef7a2574603b62d3c98789125 #1.3.2 releasae
        id: vercel-deployment
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          max_timeout: 300
      - name: Set up NodeJS
        uses: actions/setup-node@v4
      - name: Install Yarn
        run: |-
          npm install -g yarn
          yarn -v
      - name: Install dependencies
        run: yarn install --frozen-lockfile
      - name: Replace localhost URLs with Vercel deployment URL
        run: |
          DEPLOY_URL="${{ steps.vercel-deployment.outputs.url }}"
          echo "Testing against deployment: $DEPLOY_URL"
          
          # Replace localhost URLs in Lighthouse configs
          sed -i "s|http://localhost:3000|$DEPLOY_URL|g" .lighthouserc.js
          sed -i "s|http://localhost:3000|$DEPLOY_URL|g" lighthouse.mobile.config.js
      - name: Run Lighthouse audit (Desktop)
        env:
          LIGHTHOUSE_URL: ${{ steps.vercel-deployment.outputs.url }}
        run: |
          set -euo pipefail
          
          # Note: Lighthouse configs already updated with sed to use deployment URL
          yarn lighthouse:desktop
          
          # Verify desktop artifacts exist (generated by process-lhci-results.js)
          if [ ! -f ./lighthouse-results.json ] || [ ! -f ./lighthouse-desktop.html ]; then
            echo "Error: Desktop Lighthouse artifacts missing."
            exit 1
          fi
      - name: Run Lighthouse audit (Mobile)
        if: always()
        env:
          LIGHTHOUSE_URL: ${{ steps.vercel-deployment.outputs.url }}
        run: |
          set -euo pipefail
          
          yarn lighthouse:mobile
          
          # Verify mobile artifacts exist (generated by process-lhci-results.js)
          if [ ! -f ./lighthouse-mobile-results.json ] || [ ! -f ./lighthouse-mobile.html ]; then
            echo "Error: Mobile Lighthouse artifacts missing."
            exit 1
          fi
      - name: Upload Lighthouse results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: lighthouse-results
          path: |
            lighthouse-results.json
            lighthouse-mobile-results.json
            lighthouse-desktop.html
            lighthouse-mobile.html
      - name: Post Lighthouse comment
        if: always()
        uses: actions/github-script@v7
        env:
          DEPLOY_URL: ${{ steps.vercel-deployment.outputs.url }}
          RUN_ID: ${{ github.run_id }}
        with:
          script: |
            const fs = require('fs').promises;
            const path = require('path');
            
            // github-script runs from repo root, files are in repo root
            const desktopResults = JSON.parse(await fs.readFile('lighthouse-results.json', 'utf8'));
            const mobileResults = JSON.parse(await fs.readFile('lighthouse-mobile-results.json', 'utf8'));
            const deployUrl = process.env.DEPLOY_URL;
            const runId = process.env.RUN_ID;
            const artifactUrl = `https://github.com/${context.repo.owner}/${context.repo.repo}/actions/runs/${runId}`;
            
            let comment = '## üîç Lighthouse Audit Results\n\n';
            comment += `üåê **Tested deployment**: [${deployUrl}](${deployUrl})\n\n`;
            
            // Desktop scores
            comment += '### üñ•Ô∏è Desktop\n\n';
            comment += '| Category | Score | Status |\n';
            comment += '|----------|-------|--------|\n';
            
            let allPassed = true;
            for (const [key, value] of Object.entries(desktopResults.categories)) {
              if (key === 'pwa') continue; // Skip PWA category
              const score = Math.round(value.score * 100);
              const status = score === 100 ? '‚úÖ PASS' : '‚ùå FAIL';
              if (score !== 100) allPassed = false;
              comment += `| ${value.title} | ${score} | ${status} |\n`;
            }
            
            // Mobile scores
            comment += '\n### üì± Mobile\n\n';
            comment += '| Category | Score | Status |\n';
            comment += '|----------|-------|--------|\n';
            
            for (const [key, value] of Object.entries(mobileResults.categories)) {
              if (key === 'pwa') continue; // Skip PWA category
              const score = Math.round(value.score * 100);
              const status = score === 100 ? '‚úÖ PASS' : '‚ùå FAIL';
              if (score !== 100) allPassed = false;
              comment += `| ${value.title} | ${score} | ${status} |\n`;
            }
            
            comment += '\n';
            if (allPassed) {
              comment += '‚úÖ **All scores are 100%** - Quality gate passed!';
            } else {
              comment += '‚ùå **Some scores below 100%** - Please improve Lighthouse scores to 100% on all categories (Performance, Accessibility, Best Practices, SEO).\n\n';
              comment += 'üí° **Download the full HTML reports below** for detailed recommendations on what to fix.';
            }
            
            // Link to artifacts instead of inlining HTML
            comment += '\n\n---\n\n';
            comment += '### üìä Detailed Reports\n\n';
            comment += `ÔøΩ **[Download Full Reports (HTML)](${artifactUrl})**\n\n`;
            comment += 'The workflow run contains detailed HTML reports:\n';
            comment += '- `lighthouse-desktop.html` - Full desktop audit report\n';
            comment += '- `lighthouse-mobile.html` - Full mobile audit report\n';
            comment += '- `lighthouse-results.json` - Desktop results JSON\n';
            comment += '- `lighthouse-mobile-results.json` - Mobile results JSON\n\n';
            comment += '> üí° Click the link above, scroll to "Artifacts" section at the bottom, and download `lighthouse-results`';
            
            await github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: comment
            });
      - name: Check Lighthouse scores (100% required)
        if: always()
        run: |
          # Read scores and fail if not 100%
          DESKTOP_SCORES=$(jq -r '.categories | to_entries | map(select(.key != "pwa") | .value.score * 100 | floor) | all(. == 100)' lighthouse-results.json)
          MOBILE_SCORES=$(jq -r '.categories | to_entries | map(select(.key != "pwa") | .value.score * 100 | floor) | all(. == 100)' lighthouse-mobile-results.json)
          
          if [ "$DESKTOP_SCORES" != "true" ] || [ "$MOBILE_SCORES" != "true" ]; then
            echo "‚ùå Lighthouse scores must be 100% on all categories"
            exit 1
          fi
          
          echo "‚úÖ All Lighthouse scores are 100%"
